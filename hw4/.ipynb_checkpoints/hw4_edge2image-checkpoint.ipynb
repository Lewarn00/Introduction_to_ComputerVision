{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GujxwRh32UpT"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "In this homework, you will implement and train a conditional GAN model to generate complete images given only edges (or a countour sketch). You will have to design the generator and discriminator models, and also implement the training procedure of a conditional GAN, with flexibility in terms of optimizer, loss function and so on.\n",
    "\n",
    "The task consists of, given a 128x128 map of edges of a shoe image, producing a complete 128x128 image of a shoe whose edges match the input image. In other words, the task is to 'invert' edge detection (however, remember that different images can have the exact same set of edges!). For that you will use the edges2shoes dataset, which is composed by pairs (x,y) where x is an image of a shoe and y is an image of edges extracted by the HED edge detection algorithm, which we simply denote as y = edges(x).\n",
    "\n",
    "Since there are multiple different images (x1, x2, ...) that will produce the same edge map y when given as input to HED, this inversion problem is commonly framed as learning a conditional distribution p(x|y) where, for a given edge map y, we want p(x|y) to be high iff edges(x) = y and x indeed looks like a real image of a shoe (i.e. has high probability under a natural distribution of 'shoe images'). To model p(x|y) with a conditional GAN, we first define a generator G : y -> x that produces shoe images given edges, and a discriminator that assigns a scalar score (e.g. a probability) given a pair (x,y). This score should indicate whether (x,y) is a real pair (drawn from the dataset) or a fake pair (y drawn from the dataset and x = G(y)), and the specifics of how D is trained depends on the particular settings adopted to train the GAN, for example with the Jensenâ€“Shannon divergence or with the hinge loss.\n",
    "\n",
    "As before, you are expected to use google colab and run the notebook on a GPU node. This assignment consists of the following parts:\n",
    "\n",
    "(1) Prepare data by building dataset and dataloader. (already provided below)\n",
    "\n",
    "(2) Design generator/discriminator models (12 points, 6 pts each). You are free to design your own model, but it should at least be reasonable (multiple conv layers) and have the correct input/output shapes.\n",
    "\n",
    "(3) Implement training code: choose/instantiate appropriate loss functions (3 points), choose/instantiate optimizers (3 points), and implement the GAN adversarial training procedure (12 points).\n",
    "\n",
    "(4) Pick hyperparameters and design choices that give good results for the task when training the model for a reasonable amount of time (24 points). More specifically, your model will be evaluated in terms of FID (a metric commonly used to evaluate GANs, which aims to capture how 'distant' fake images are from real ones, both in terms of quality and diversity) and, to some extent, visual assessment of generated images.\n",
    "\n",
    "(5) Describe what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network. Report final FID after reasonable training time (e.g. at least 3 epochs for big models) including images of at least 8 triples (edge, shoe, fake_shoe) for (shoe, edge) pairs in the validation dataset in a writeup: hw4.pdf (6 points).\n",
    "\n",
    "It is highly suggested that you read the pix2pix paper (https://arxiv.org/abs/1611.07004), as it trains a conditional GAN on this very dataset. Feel free to use it as inspiration when designing the models and setting up the training pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzmHjyUYDvPd"
   },
   "source": [
    "The two cells below will download and untar the edges2shoes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pOX-QwxaKbb",
    "outputId": "d07058a8-077c-4e80-8041-cbb59857e65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget -N http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/edges2shoes.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s4R60ojxA79V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Error opening archive: Failed to open './edges2shoes.tar.gz'\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zxf ./edges2shoes.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOHEsSiRZ637"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHlwFWjxD4DY"
   },
   "source": [
    "The custom dataset below can be used to directly draw samples (x,y), where x is a shoe image and y = edges(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3keBOkAZSop"
   },
   "outputs": [],
   "source": [
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    for root, _, fnames in sorted(os.walk(dir)):\n",
    "        for fname in fnames:\n",
    "            images.append(os.path.join(root, fname))\n",
    "    return images\n",
    "\n",
    "class Edges2ShoesDataset(Dataset):\n",
    "    def __init__(self, dataroot, phase):\n",
    "        super(Edges2ShoesDataset).__init__()\n",
    "        self.dir_xy = os.path.join(dataroot, phase)\n",
    "        self.xy_paths = sorted(make_dataset(self.dir_xy))\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(128),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        xy_path = self.xy_paths[index]\n",
    "        xy = Image.open(xy_path).convert('RGB')\n",
    "        w, h = xy.size\n",
    "        w2 = int(w / 2)\n",
    "        x = xy.crop((w2, 0, w, h))\n",
    "        y = xy.crop((0, 0, w2, h))\n",
    "\n",
    "        x = self.transform(x)\n",
    "        y = self.transform(y)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xy_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyZIogFc49QD"
   },
   "outputs": [],
   "source": [
    "train_dataset = Edges2ShoesDataset(\"edges2shoes\", \"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_dataset = Edges2ShoesDataset(\"edges2shoes\", \"val\")\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7sW9jgoElye"
   },
   "source": [
    "Let's look at one (x,y) sample from the training split of edges2shoes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "4-YyImm_GsB_",
    "outputId": "61ccbcac-2b49-487b-e1b3-c6c91bedca6d"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "def show(x):\n",
    "    img = (x.data.cpu().permute(1, 2, 0).numpy() + 1) * 255/2.0\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2_imshow(img)\n",
    "\n",
    "shoes, edges = next(iter(train_dataloader))\n",
    "show(edges[0])\n",
    "show(shoes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eys3VARPMHs"
   },
   "source": [
    "In the next section you have to design and implement a generator and a discriminator model. Recall that the generator should map edge images (3x128x128 tensors) to shoe images (3x128x128 tensors), while the discriminator should map shoe, edge pairs (two 3x128x128 tensors) to a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG3YgSMjK_-0"
   },
   "outputs": [],
   "source": [
    "# design your own Generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2APGGP4Oxom"
   },
   "outputs": [],
   "source": [
    "# design your own Discriminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ct2esPLAP2LG"
   },
   "source": [
    "Next you have to instantiate the losses that you will use to train the model. The pix2pix paper uses a reconstruction loss along with the standard GAN objective: in particular, the L1 reconstruction between (shoe, G(edge)) for a (shoe, edge) training pair, with the L1 loss being scaled up by a factor of 100 when adding to the GAN loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKP2-ZdiP-KW"
   },
   "outputs": [],
   "source": [
    "# instantiate losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnVdnOrxQl32"
   },
   "source": [
    "Instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XevBn3EuPiM-"
   },
   "outputs": [],
   "source": [
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wymVCQCsQgrZ"
   },
   "source": [
    "and the necessary optimizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM9Yx3uJRX7y"
   },
   "outputs": [],
   "source": [
    "# instantiate optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvC9FV2VQrxj"
   },
   "source": [
    "Finally, implement the GAN training objective below, where the discriminator is trained to distinguish real and fake pairs, while the generator is trained to fool the discriminator (and to also yield good reconstructions, in case you use a reconstruction term as in pix2pix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "n8hkZJLRRtTo",
    "outputId": "815dc741-5b21-4250-eab2-e5d18a8c926e"
   },
   "outputs": [],
   "source": [
    "# implement adversarial training for GANs\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (shoes, edges) in enumerate(train_dataloader):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acygkUZNWo8U"
   },
   "source": [
    "Once the conditional GAN is trained, we can view how real and fake shoes look like for the same edge map in the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "s7DVkYl3FM4E",
    "outputId": "1d461e12-cc0e-4e33-c22f-6f28dfd91175"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    shoes, edges = next(iter(val_dataloader))\n",
    "    shoes, edges = shoes.cuda(), edges.cuda()\n",
    "    fake_shoes = generator(edges)\n",
    "\n",
    "    stacked_edges = torch.cat([edge for edge in edges[:8]], dim=2)\n",
    "    stacked_shoes = torch.cat([shoe for shoe in shoes[:8]], dim=2)\n",
    "    stacked_fake_shoes = torch.cat([fake_shoe for fake_shoe in fake_shoes[:8]], dim=2)\n",
    "\n",
    "    show(stacked_edges)\n",
    "    show(stacked_shoes)\n",
    "    show(stacked_fake_shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnDI_DjbW1D3"
   },
   "source": [
    "Finally, the cell below takes a subset of the training data and computes the FID (lower is better). A reasonable model should be able to achieve around 20 FID after a few training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyIXYPWCH4Br",
    "outputId": "bc2ba23c-c9d3-4262-9193-46ecb95162f4"
   },
   "outputs": [],
   "source": [
    "import fid\n",
    "eval_dataset = Edges2ShoesDataset(\"edges2shoes\", \"train\")\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "print(fid.get_fid(eval_dataloader, generator))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Homework 4 - Pix2Pix.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
